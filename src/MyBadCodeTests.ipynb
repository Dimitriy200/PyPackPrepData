{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подтягиваем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PrepData as prd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем входные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Массивы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 1.,  1., nan]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOOD_dataFrame = np.array([[1.0, 1.0, 1.0],\n",
    "                           [1.0, 1.0, 1.0],\n",
    "                           [1.0, 1.0, 1.0]])\n",
    "\n",
    "BAD_dataFrame  = np.array([[np.nan, np.nan, np.nan],\n",
    "                           [1,      1,      1],\n",
    "                           [1,      1,      np.nan,]])\n",
    "\n",
    "BAD_dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create pipline successfull\n"
     ]
    }
   ],
   "source": [
    "prepData = prd.PrepData()\n",
    "\n",
    "simple_inputer = KNNImputer(n_neighbors = 2)\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "pipeline = Pipeline([('imputer', simple_inputer),('scaler', std_scaler)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наконец тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add_col_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1. nan]]\n",
      "str --> 3 \n",
      "col --> 3\n",
      "Check NULL values in dataframe successfull result is True\n",
      "Add column with indexes in dataframe successfull\n",
      "[[nan nan nan nan]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 1.  1.  1. nan]]\n"
     ]
    }
   ],
   "source": [
    "print(BAD_dataFrame)\n",
    "print(prepData.add_col_indexes(BAD_dataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "str --> 3 \n",
      "col --> 3\n",
      "Check NULL values in dataframe error\n",
      "Add column with indexes in dataframe successfull\n",
      "[[0. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [2. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(GOOD_dataFrame)\n",
    "print(prepData.add_col_indexes(GOOD_dataFrame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delete_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1. nan]]\n",
      "Delete columns with names in dataframe successfull\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  1. nan]]\n"
     ]
    }
   ],
   "source": [
    "print(BAD_dataFrame)\n",
    "print(prepData.delete_names(BAD_dataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "Delete columns with names in dataframe successfull\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(GOOD_dataFrame)\n",
    "print(prepData.delete_names(GOOD_dataFrame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delete_nan_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1. nan]]\n",
      "str = 3\n",
      "col = 3\n",
      "Check NULL values in dataframe successfull result is True\n",
      "Check NULL values in dataframe successfull result is False\n",
      "res_dataFrame = [[0. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "Check NULL values in dataframe successfull result is True\n",
      "Delete NULL lines in dataframe successfull\n",
      "res =\n",
      " [[1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(BAD_dataFrame)\n",
    "print(\"res =\\n\", prepData.delete_nan_str(BAD_dataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "str = 3\n",
      "col = 3\n",
      "Check NULL values in dataframe successfull result is False\n",
      "res_dataFrame = [[0. 0. 0.]\n",
      " [1. 1. 1.]]\n",
      "Check NULL values in dataframe successfull result is False\n",
      "res_dataFrame = [[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "Check NULL values in dataframe successfull result is False\n",
      "res_dataFrame = [[0. 0. 0.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "Delete NULL lines in dataframe successfull\n",
      "res =\n",
      " [[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(GOOD_dataFrame)\n",
    "print(\"res =\\n\", prepData.delete_nan_str(GOOD_dataFrame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to_standardization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1. nan]]\n",
      "str --> 3 \n",
      "col --> 3\n",
      "Check NULL values in dataframe successfull result is True\n",
      "Add column with indexes in dataframe successfull\n",
      "Delete columns with names in dataframe successfull\n",
      "str = 2\n",
      "col = 4\n",
      "Check NULL values in dataframe successfull result is False\n",
      "res_dataFrame = [[0. 0. 0. 0.]\n",
      " [0. 1. 1. 1.]]\n",
      "Check NULL values in dataframe successfull result is True\n",
      "Delete NULL lines in dataframe successfull\n",
      "Standartization dataframe successfull\n",
      "res =\n",
      " [[0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(BAD_dataFrame)\n",
    "print(\"res =\\n\", prepData.to_standardization_df(BAD_dataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "str --> 3 \n",
      "col --> 3\n",
      "Check NULL values in dataframe successfull result is False\n",
      "Add column with indexes in dataframe successfull\n",
      "Delete columns with names in dataframe successfull\n",
      "str = 3\n",
      "col = 4\n",
      "Check NULL values in dataframe successfull result is False\n",
      "res_dataFrame = [[0. 0. 0. 0.]\n",
      " [0. 1. 1. 1.]]\n",
      "Check NULL values in dataframe successfull result is False\n",
      "res_dataFrame = [[0. 0. 0. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "Check NULL values in dataframe successfull result is False\n",
      "res_dataFrame = [[0. 0. 0. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [2. 1. 1. 1.]]\n",
      "Delete NULL lines in dataframe successfull\n",
      "Standartization dataframe successfull\n",
      "res =\n",
      " [[0. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [2. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(GOOD_dataFrame)\n",
    "print(\"res =\\n\", prepData.to_standardization_df(GOOD_dataFrame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### employ_Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dir = \"C:/Users/Dmitriy/Desktop/Univer/Diplom/diplom_autoencoder/data/raw/tests\"\n",
    "out_dir = \"C:/Users/Dmitriy/Desktop/Univer/Diplom/diplom_autoencoder/data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting a list of documents...\n",
      "   .../Small_BAD_test_FD001.csv\n",
      "   .../Small_GOOD_test_FD001.csv\n",
      "Documents have been received\n",
      "  Processed -->  Small_BAD_test_FD001.csv\n",
      "Check NULL values in dataframe successfull result is True\n",
      "Dataset is BAD Starting standartization dataframe...\n",
      "str --> 5 \n",
      "col --> 4\n",
      "Check NULL values in dataframe successfull result is True\n",
      "Add column with indexes in dataframe successfull\n",
      "Delete columns with names in dataframe successfull\n",
      "str = 4\n",
      "col = 5\n",
      "Check NULL values in dataframe successfull result is True\n",
      "Check NULL values in dataframe successfull result is False\n",
      "res_dataFrame = [[ 0.0e+00  0.0e+00  0.0e+00  0.0e+00  0.0e+00]\n",
      " [ 1.0e+00  1.0e+00  2.0e+00 -2.7e-03 -3.0e-04]]\n",
      "Check NULL values in dataframe successfull result is True\n",
      "Check NULL values in dataframe successfull result is True\n",
      "Delete NULL lines in dataframe successfull\n",
      "Standartization dataframe successfull\n",
      "Dataset is GOOD  Starting employ pipeline...\n",
      "  Processed -->  Small_GOOD_test_FD001.csv\n",
      "Check NULL values in dataframe successfull result is False\n",
      "Check NULL values in dataframe successfull result is False\n",
      "Check NULL values in dataframe successfull result is False\n",
      "Check NULL values in dataframe successfull result is False\n",
      "Dataset is GOOD  Starting employ pipeline...\n",
      "Preprocess data finished successfull\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepData.employ_Pipline(inp_dir,\n",
    "                        out_dir,\n",
    "                        prepData.defaultPipline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
